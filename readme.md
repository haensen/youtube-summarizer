## Which model can be used when self-hosting?

| Model                         | Notes                                                         |
| ----------------------------- | ------------------------------------------------------------- |
| Gemma 3 1B Q3_K_L             | Not recommended, hallucinates                                 |
| Gemma 2 2B Q4_K_M             | OKish summaries, fast operation                               |
| **Gemma 3 4B Q4_K_M**         | Recommended, more coherent language than with Gemma 2 2B      |
| Larger models                 | Marginal additional benefits, slower                          |
